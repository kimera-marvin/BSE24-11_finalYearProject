{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPx4pyazAk8KipW2NGjeYhq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"id":"XkIFhu7h3Jaw","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"error","timestamp":1717615978830,"user_tz":-180,"elapsed":8,"user":{"displayName":"Gilbert Ahabwe","userId":"13931581977278214119"}},"outputId":"32411a3f-804a-4c44-c582-9efdc8abb52b"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'drive' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-1ac089313096>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from google.colab import files\n","import zipfile\n","drive.mount('/content/drive')\n","\n","\n","# Upload files directly\n","# uploaded = files.upload()\n","\n","# # Extract the uploaded zip files\n","# for filename in uploaded.keys():\n","#     zip_ref = zipfile.ZipFile(filename, 'r')\n","#     zip_ref.extractall('/content')\n","#     zip_ref.close()\n","\n","# # Define paths for the dataset\n","# train_dir = '/content/Content/datasets/train'\n","# val_dir = '/content/Content/datasets/val'\n","# test_dir = '/content/Content/datasets/test'\n","\n","# Define the path where your dataset folders are located in Google Drive\n","# Adjust the paths below to match the locations of your training, validation, and test folders\n","train_dir = '/content/drive/MyDrive/Content/datasets/train'\n","val_dir = '/content/drive/MyDrive/Content/datasets/val'\n","test_dir = '/content/drive/MyDrive/Content/datasets/test'\n","\n","\n","# Function to list directories and count images\n","def list_directories_and_count_images(path):\n","    for root, dirs, files in os.walk(path):\n","        print(f'Directory: {root}')\n","        if len(files) > 0:\n","            print(f'Contains {len(files)} files')\n","\n","# Check the contents of each directory\n","print(\"Checking training directory:\")\n","list_directories_and_count_images(train_dir)\n","print(\"\\nChecking validation directory:\")\n","list_directories_and_count_images(val_dir)\n","print(\"\\nChecking test directory:\")\n","list_directories_and_count_images(test_dir)\n","\n","# Define ImageDataGenerators for loading and augmenting images\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   rotation_range=20,\n","                                   width_shift_range=0.2,\n","                                   height_shift_range=0.2,\n","                                   shear_range=0.2,\n","                                   zoom_range=0.2,\n","                                   horizontal_flip=True,\n","                                   fill_mode='nearest')\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    target_size=(150, 150),\n","                                                    batch_size=32,\n","                                                    class_mode='categorical',  # Change to categorical\n","                                                    color_mode='grayscale')\n","\n","val_generator = val_datagen.flow_from_directory(val_dir,\n","                                                target_size=(150, 150),\n","                                                batch_size=32,\n","                                                class_mode='categorical',  # Change to categorical\n","                                                color_mode='grayscale')\n","\n","test_generator = test_datagen.flow_from_directory(test_dir,\n","                                                  target_size=(150, 150),\n","                                                  batch_size=32,\n","                                                  class_mode='categorical',  # Change to categorical\n","                                                  color_mode='grayscale')\n","\n","# Print the number of samples in each generator\n","print(f'Number of training samples: {train_generator.samples}')\n","print(f'Number of validation samples: {val_generator.samples}')\n","print(f'Number of test samples: {test_generator.samples}')\n","\n","# Ensure that we have sufficient images to proceed with training\n","if train_generator.samples > 0 and val_generator.samples > 0 and test_generator.samples > 0:\n","    # Define the CNN model\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n","        MaxPooling2D((2, 2)),\n","        Conv2D(64, (3, 3), activation='relu'),\n","        MaxPooling2D((2, 2)),\n","        Conv2D(128, (3, 3), activation='relu'),\n","        MaxPooling2D((2, 2)),\n","        Conv2D(128, (3, 3), activation='relu'),\n","        MaxPooling2D((2, 2)),\n","        Flatten(),\n","        Dense(512, activation='relu'),\n","        Dropout(0.5),\n","        Dense(3, activation='softmax')  # Change to 3 units and softmax activation\n","    ])\n","\n","    # Compile the model\n","    model.compile(loss='categorical_crossentropy',  # Change to categorical_crossentropy\n","                  optimizer='adam',\n","                  metrics=['accuracy'])\n","\n","    # Define callbacks\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n","    model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n","\n","    # Train the model\n","    history = model.fit(train_generator,\n","                        steps_per_epoch=max(1, train_generator.samples // train_generator.batch_size),\n","                        epochs=50,\n","                        validation_data=val_generator,\n","                        validation_steps=max(1, val_generator.samples // val_generator.batch_size),\n","                        callbacks=[early_stopping, model_checkpoint])\n","\n","    # Load the best model\n","    model.load_weights('best_model.h5')\n","\n","    # Evaluate the model on the test set\n","    test_loss, test_acc = model.evaluate(test_generator, steps=max(1, test_generator.samples // test_generator.batch_size))\n","    print(f'Test accuracy: {test_acc:.2f}')\n","\n","    # Plot training history\n","    plt.figure(figsize=(12, 4))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['accuracy'], label='Training Accuracy')\n","    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","    plt.legend()\n","    plt.title('Accuracy')\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.legend()\n","    plt.title('Loss')\n","\n","    plt.show()\n","    model_path = '/content/drive/MyDrive/first_draft_classifier_v_12.h5'  # Replace with your desired path\n","    model.save(model_path)\n","\n","else:\n","    print(\"Please ensure that your dataset directories contain images and try again.\")\n"]}]}